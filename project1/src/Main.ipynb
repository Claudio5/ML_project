{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (CS-433)\n",
    "## Class Project 1\n",
    "Simon Canales, Jordan Willemin, Claudio Loureiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from utils import *\n",
    "\n",
    "# Plot libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pred, training_data, ids_tr = load_csv_data(\"../data/train.csv\")\n",
    "testing_pred, testing_data, ids_te = load_csv_data(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we preprocess our data, we observe that we have flags values as -999. We set it for now to 0 and this will be then treated correctly when standardizing data when doing cross-validation. Also there is a column that contains only 0, 1 and 2. Thus we increase this feature by 1 in order to not consider this value as the others 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = training_data[:,29]\n",
    "x2 = training_data[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x1,x2,cap = training_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_value = -999\n",
    "training_data[training_data==wrong_value] = 0\n",
    "testing_data[testing_data==wrong_value] = 0\n",
    "training_data[:,22] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the least squares gradient descent. We fit a polynomial to our input data of degree 2. Then we do our cross-validation with $k_{fold} = 5$. After testing some values we quickly remark that increasing the maximum iterations above 100 and decreasing gamma below 0.01 does no longer increase the accuracy dramtically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse:  0.35087575462902754\n",
      "Rmse:  0.8377060995707594\n",
      "Accuracy:  0.749096\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 2\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.01\n",
    "\n",
    "k_fold = 5\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(least_squares_GD, \n",
    "                                                                                   compute_mse, tx, training_pred, indexes_te, \n",
    "                                                                                   indexes_tr, k_fold, True, \n",
    "                                                                                   (initial_w, max_iters, gamma))\n",
    "\n",
    "print('Mse: ', format(mse_te_mean))\n",
    "print('Rmse: ', format(rmse_te_mean))\n",
    "print('Accuracy: ', format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least squares stochastic gradient descent. Agains it works as the least squares gradient descent but at each iteration we only take one sample of the dataset. The we naturally have to do more iterations than the gradient descent. Again we fit a polynomial to the dataset and perform a cross-validation with $k_{fold} = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse:  0.49198847363399467\n",
      "Rmse:  0.9919561216444956\n",
      "Accuracy:  0.6828520000000002\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 5\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "max_iters = 500\n",
    "gamma = 0.00001\n",
    "\n",
    "k_fold = 5\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(least_squares_SGD, \n",
    "                                                                                  compute_mse, tx, training_pred, indexes_te, \n",
    "                                                                                  indexes_tr, k_fold, True, \n",
    "                                                                                  (initial_w, max_iters, gamma))\n",
    "\n",
    "print('Mse: ', format(mse_te_mean))\n",
    "print('Rmse: ', format(rmse_te_mean))\n",
    "print('Accuracy: ', format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to other methods least squares is not an iterative method. Instead we have to resolve a system in order to minimize our weight matrix. Again, we fit a polynomial to the data set of degree 3 and perform a cross-validation with $k_{fold} = 4$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse:  0.3222919637939099\n",
      "Rmse:  0.8028598430534559\n",
      "Accuracy:  0.780356\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 3\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "\n",
    "k_fold = 4\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(least_squares, \n",
    "                                                                                  compute_mse, tx, training_pred, indexes_te, \n",
    "                                                                                  indexes_tr, k_fold, True)\n",
    "\n",
    "print('Mse: ', format(mse_te_mean))\n",
    "print('Rmse: ', format(rmse_te_mean))\n",
    "print('Accuracy: ', format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge regression is an improved version of the least squares method denoted above. It adds a regularization term. This method proved allowed us to have the best results in term of accuracy. Thus we will optimize our parameters to achieve the best possible accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse:  29179899974.323742\n",
      "Rmse:  241577.7306554714\n",
      "Accuracy:  0.439816\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 15\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "lambda_ = 1e-15\n",
    "\n",
    "k_fold = 5\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(ridge_regression, \n",
    "                                                                                  compute_mse, tx, training_pred, indexes_te, \n",
    "                                                                                  indexes_tr, k_fold, True, (lambda_,))\n",
    "\n",
    "print('Mse: ', format(mse_te_mean))\n",
    "print('Rmse: ', format(rmse_te_mean))\n",
    "print('Accuracy: ', format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try to find the lambda that gives us the best accuracy. We will iterate through a list of lambdas and perform a cross validation for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26804d2eb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly_degree = 12\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "lambda_vec = np.logspace(-7, -17, 10)\n",
    "accuracy_vec = []\n",
    "\n",
    "k_fold = 4\n",
    "\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "\n",
    "for lambda_ in lambda_vec:\n",
    "    mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(ridge_regression, \n",
    "                                                                                      compute_mse, tx, training_pred, indexes_te, \n",
    "                                                                                      indexes_tr, k_fold, True, (lambda_,))\n",
    "    accuracy_vec.append(accuracy)\n",
    "    \n",
    "plt.semilogx(lambda_vec, accuracy_vec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.   9.  10.  11.  12.  13.  14.]\n",
      "[  1.00000000e-08   1.00000000e-09   1.00000000e-10   1.00000000e-11\n",
      "   1.00000000e-12   1.00000000e-13   1.00000000e-14   1.00000000e-15\n",
      "   1.00000000e-16]\n"
     ]
    }
   ],
   "source": [
    "degrees_vec = np.linspace(8, 18, 10)\n",
    "lambdas_vec = np.logspace(-8, -16, 9)\n",
    "print(degrees_vec)\n",
    "print(lambdas_vec)\n",
    "k_fold = 5\n",
    "\n",
    "rmse_te_mean_arr = np.zeros((len(lambdas_vec), len(degrees_vec)))\n",
    "mse_te_mean_arr = np.zeros_like(rmse_te_mean_arr)\n",
    "accuracy_arr = np.zeros_like(rmse_te_mean_arr)\n",
    "\n",
    "for i, degree in enumerate(degrees_vec):\n",
    "    tx = build_poly(training_data, int(degree))\n",
    "    indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "    for j, lambda_ in enumerate(lambda_vec):\n",
    "        print(i,j)\n",
    "        mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(ridge_regression, \n",
    "                                                                                    compute_mse, tx, training_pred, indexes_te, \n",
    "                                                                                    indexes_tr, k_fold, True, (lambda_,))\n",
    "        accuracy_arr[j][i] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pred_log = training_pred.copy()\n",
    "training_pred_log[training_pred_log==-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative log likelihood:  0.6920867021048016\n",
      "Rmse:  1.1765089902799737\n",
      "Accuracy:  0.6768280000000001\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 10\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "max_iters = 200\n",
    "gamma = 0.00001\n",
    "\n",
    "k_fold = 4\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(logistic_regression, loss_logistic_regression,\n",
    "                                                                                  tx, training_pred_log, indexes_te, \n",
    "                                                                                  indexes_tr, k_fold, True, \n",
    "                                                                                  (initial_w, max_iters, gamma))\n",
    "\n",
    "print('Negative log likelihood: ', format(mse_te_mean))\n",
    "print('Rmse: ', format(rmse_te_mean))\n",
    "print('Accuracy: ', format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative log likelihood:  0.6920153614956716\n",
      "Rmse:  1.176448351178811\n",
      "Accuracy:  0.67778\n"
     ]
    }
   ],
   "source": [
    "poly_degree = 12\n",
    "tx = build_poly(training_data, poly_degree)\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "lambda_ = 1\n",
    "max_iters = 200\n",
    "gamma = 0.00001\n",
    "\n",
    "k_fold = 4\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy = cross_validation(reg_logistic_regression, \n",
    "                                                                                  reg_logistic_regression_loss,\n",
    "                                                                                  tx, training_pred_log, indexes_te, \n",
    "                                                                                  indexes_tr, k_fold, True, \n",
    "                                                                                  (lambda_, initial_w, max_iters, gamma),\n",
    "                                                                                  (lambda_,))\n",
    "\n",
    "print('Negative log likelihood: ', format(mse_te_mean))\n",
    "print('Rmse: ', format(rmse_te_mean))\n",
    "print('Accuracy: ', format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
