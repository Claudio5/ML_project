{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_nparts(array, n):\n",
    "    k, m = divmod(len(array), n)\n",
    "    return (array[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_indexes(x, y, k_fold, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    \n",
    "    # Set seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate random indices\n",
    "    subdivision = int(len(x)/k_fold)\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split_te = list(split_nparts(indices, k_fold))\n",
    "    index_split_tr = np.zeros((k_fold, len(x) - subdivision))\n",
    "\n",
    "    for i, ind_te in enumerate(index_split_te):\n",
    "        index_split_tr[i,:] = [ind for ind in indices if ind not in list(index_split_te[i])]\n",
    "\n",
    "    return index_split_te, index_split_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x_tr, isTestingData = False, x_te = None):\n",
    "    \"\"\" Standardize the testing data by substracting the mean and dividing\n",
    "    by the variance. If isTestingData is true it standardize the testing data \n",
    "    only using the training data \"\"\"\n",
    "    \n",
    "    centered_data = x_tr - np.mean(x_tr, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    \n",
    "    if(isTestingData and x_te is not None):\n",
    "        centered_data_te = x_te - np.mean(x_tr, axis=0)\n",
    "        std_data_te = centered_data_te / np.std(centered_data, axis=0)\n",
    "\n",
    "    return std_data, std_data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(optim_method, loss_function, tx, y, indexes_te, indexes_tr,\n",
    "                    k_fold, args_optim = (), args_loss = ()):\n",
    "    err_tr_list = []\n",
    "    err_te_list = []\n",
    "    accuracy_list = []\n",
    "    for i in range(k_fold):\n",
    "        x_te = x[indexes_te[i]]\n",
    "        y_te = y[indexes_te[i]]\n",
    "        x_tr = x[(indexes_tr[i]).astype(int)]\n",
    "        y_tr = y[(indexes_tr[i]).astype(int)]\n",
    "\n",
    "        x_tr, x_te = standardize(x_tr, True, x_te)\n",
    "\n",
    "        w, err_tr = optim_method(y_tr, x_tr, *args_optim)\n",
    "\n",
    "        err_te = loss_function(y, tx, w, *args_loss)\n",
    "\n",
    "        y_predicted = predict_labels(w, x_te)\n",
    "        \n",
    "        accuracy_list.append(np.sum(np.equal(y_predicted, y_te)/len(y_te)))\n",
    "        \n",
    "        err_tr_list.append(err_tr)\n",
    "        err_te_list.append(err_te)\n",
    "        \n",
    "    mse_tr_mean = np.mean(err_tr_list)\n",
    "    mse_te_mean = np.mean(err_te_list)\n",
    "    accuracy_mean = np.mean(accuracy_list)\n",
    "\n",
    "    return mse_tr_mean, mse_te_mean, accuracy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.1,0.2],[0.1,0.33],[0.11,0.4],[0.1,0.9],[0.2,0.8],[0.1,0.1]])\n",
    "y = np.array([1,1,-1,-1,1,-1])\n",
    "w = np.zeros(x.shape[1])\n",
    "\n",
    "k_fold = 3\n",
    "\n",
    "index_te, index_tr = get_split_indexes(x,y,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48432933737208833, 0.49975411098122596, 0.5)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares_GD, compute_mse, x, y, index_te, index_tr, k_fold, (w, 10, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4800625940687604, 0.50015252248561759, 0.5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares_SGD, compute_mse, x, y, index_te, index_tr, k_fold, (w, 10, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for least squares analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35742270690435518, 0.6019794683083538, 0.5)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares, compute_mse, x, y, index_te, index_tr, k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39641465920534397, 0.49848741293835275, 0.5)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "cross_validation(ridge_regression, compute_mse, x, y, index_te, index_tr, k_fold, (lambda_,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67701474914971094, 0.69302239588289749, 0.5)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(logistic_regression, loss_logistic_regression, x, y, index_te, index_tr, k_fold, (w, 10, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.57261241819429809, 0.69540134788635488, 0.66666666666666663)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "cross_validation(reg_logistic_regression, reg_logistic_regression_loss, x, y, index_te, index_tr, k_fold, \n",
    "                 (lambda_, w, 10, 0.1), (lambda_,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
