{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from implementations import *\n",
    "from proj1_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pred, training_data, ids_tr = load_csv_data(\"../data/train.csv\")\n",
    "testing_pred, testing_data, ids_te = load_csv_data(\"../data/test.csv\")\n",
    "training_data[training_data == -999] = 0\n",
    "testing_data[testing_data == -999] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    poly = np.ones((len(x), 1))\n",
    "    for deg in range(1, degree+1):\n",
    "        poly = np.c_[poly, np.power(x, deg)]\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_nparts(array, n):\n",
    "    k, m = divmod(len(array), n)\n",
    "    return (array[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_indexes(x, y, k_fold, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "\n",
    "    # Set seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Generate random indices\n",
    "    subdivision = int(len(x)/k_fold)\n",
    "    indices = np.random.permutation(len(y))\n",
    "\n",
    "    index_split_te = list(split_nparts(indices, k_fold))\n",
    "    index_split_tr = np.zeros((k_fold, len(x) - subdivision))\n",
    "\n",
    "    for i in range(0, k_fold):\n",
    "        index_split_tr[i,:] = list(set(range(x.shape[0])) - set(index_split_te[i]))\n",
    "\n",
    "    return index_split_te, index_split_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x_tr, isTestingData = False, x_te = None):\n",
    "    \"\"\" Standardize the testing data by substracting the mean and dividing\n",
    "    by the variance. If isTestingData is true it standardize the testing data \n",
    "    only using the training data \"\"\"\n",
    "    \n",
    "    centered_data = x_tr - np.mean(x_tr, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    \n",
    "    if(isTestingData and x_te is not None):\n",
    "        centered_data_te = x_te - np.mean(x_tr, axis=0)\n",
    "        std_data_te = centered_data_te / np.std(centered_data, axis=0)\n",
    "\n",
    "    return std_data, std_data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(optim_method, loss_function, tx, y, indexes_te, indexes_tr,\n",
    "                    k_fold, isBuildPoly = False, args_optim = (), args_loss = ()):\n",
    "    err_tr_list = []\n",
    "    err_te_list = []\n",
    "    accuracy_list = []\n",
    "    for i in range(k_fold):\n",
    "        x_te = tx[indexes_te[i]]\n",
    "        y_te = y[indexes_te[i]]\n",
    "        x_tr = tx[(indexes_tr[i]).astype(int)]\n",
    "        y_tr = y[(indexes_tr[i]).astype(int)]\n",
    "\n",
    "        if not isBuildPoly:\n",
    "            x_tr, x_te = standardize(x_tr, True, x_te)\n",
    "        else:\n",
    "            # Does not take into account the column containing only ones to avoid a std of 0\n",
    "            # It happens when we try to add polynomial features\n",
    "            x_tr[:,1:], x_te[:,1:] = standardize(x_tr[:,1:], True, x_te[:,1:])\n",
    "            \n",
    "\n",
    "        w, err_tr = optim_method(y_tr, x_tr, *args_optim)\n",
    "\n",
    "        err_te = loss_function(y_te, x_te, w, *args_loss)\n",
    "        y_predicted = predict_labels(w, x_te)\n",
    "        \n",
    "        accuracy_list.append(np.sum(np.equal(y_predicted, y_te)/len(y_te)))\n",
    "\n",
    "        err_tr_list.append(err_tr)\n",
    "        err_te_list.append(err_te)\n",
    "\n",
    "    mse_tr_mean = np.mean(err_tr_list)\n",
    "    mse_te_mean = np.mean(err_te_list)\n",
    "    rmse_tr_mean = np.sqrt(2*mse_tr_mean)\n",
    "    rmse_te_mean = np.sqrt(2*mse_te_mean)\n",
    "    accuracy_mean = np.mean(accuracy_list)\n",
    "\n",
    "    return mse_tr_mean, mse_te_mean, rmse_tr_mean, rmse_te_mean, accuracy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80131906480355064,\n",
       " 0.80440364983593959,\n",
       " 1.265953446856203,\n",
       " 1.2683876771996325,\n",
       " 0.67111600000000005)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tx = training_data \n",
    "tx = build_poly(training_data, 2) \n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "max_iters = 40\n",
    "gamma = 0.01\n",
    "\n",
    "k_fold = 4\n",
    "indexes_te, indexes_tr = get_split_indexes(training_data, training_pred, k_fold)\n",
    "cross_validation(least_squares_GD, compute_mse, tx, training_pred, indexes_te, indexes_tr,\n",
    "                 k_fold, True, (initial_w, max_iters, gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48432933737208833, 0.49975411098122596, 0.5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares_GD, compute_mse, x, y, index_te, index_tr, k_fold, (w, 10, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for least squares SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49266641255846966, 0.50013040213696258, 0.5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares_SGD, compute_mse, x, y, index_te, index_tr, k_fold, (w, 10, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for least squares analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35742270690435518, 0.60197946830835392, 0.5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(least_squares, compute_mse, x, y, index_te, index_tr, k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39641465920534397, 0.49848741293835275, 0.5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "cross_validation(ridge_regression, compute_mse, x, y, index_te, index_tr, k_fold, (lambda_,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67701474914971094, 0.69302239588289749, 0.5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(logistic_regression, loss_logistic_regression, x, y, index_te, index_tr, k_fold, (w, 10, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV for regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.57261241819429809, 0.69540134788635488, 0.66666666666666663)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ = 0.1\n",
    "cross_validation(reg_logistic_regression, reg_logistic_regression_loss, x, y, index_te, index_tr, k_fold, \n",
    "                 (lambda_, w, 10, 0.1), (lambda_,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
